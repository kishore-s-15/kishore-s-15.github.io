<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> MemeSense | Kishore Sampath </title> <meta name="author" content="Kishore Sampath"> <meta name="description" content="A Multimodal Framework for Meme Analysis using Enhanced CLIP"> <meta name="keywords" content="kishore-sampath, ai, machine-learning, data-science, researcher"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kishore-s-15.github.io/projects/3_project/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Kishore Sampath </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/personal/">personal </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">MemeSense</h1> <p class="post-description">A Multimodal Framework for Meme Analysis using Enhanced CLIP</p> </header> <article> <h3 id="overview">Overview</h3> <p>MemeSense is a sophisticated multimodal framework that leverages OpenAI’s CLIP architecture for comprehensive meme analysis. The system combines feature adapters and cosine classifiers with a semantic-aware initialization strategy to achieve high-performance classification across multiple tasks. By implementing a multi-modal architecture with enhanced CLIP features, the system effectively processes both visual and textual components of memes to perform tasks such as humor detection, hate speech identification, target classification, and stance analysis.</p> <h3 id="architecture">Architecture</h3> <p>The MemeSense framework is built upon a multi-component architecture designed to process both visual and textual elements of memes through specialized modules. Its core implementation uses CLIP’s pre-trained knowledge combined with custom feature adapters and a semantic-aware initialization strategy. This design enables efficient processing of multimodal content while maintaining the rich pre-trained knowledge of the CLIP model.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/projects/memeclip_architecture.png" alt="Complete system architecture of MemeSense" title="Complete system architecture of MemeSense"> </div> </div> <div class="caption"> Complete system architecture showing CLIP encoders, feature adapters, and classification components </div> <h3 id="base-architecture-and-feature-processing">Base Architecture and Feature Processing</h3> <p>The system utilizes CLIP’s Vision Transformer (ViT-L/14) for processing images and a text encoder for handling textual content. The vision encoder processes 224x224 RGB images through 24 transformer layers, while the text encoder handles up to 77 tokens through 12 transformer layers. Both encoders output 768-dimensional feature vectors that capture rich semantic information from their respective modalities. These base encoders are kept frozen to preserve CLIP’s pre-trained knowledge while additional components are trained for task-specific optimization.</p> <h3 id="feature-adaptation-and-enhancement">Feature Adaptation and Enhancement</h3> <p>Building on the base architecture, MemeSense implements a sophisticated feature adaptation mechanism. The system first projects the initial 768-dimensional features to a higher 1024-dimensional space using configurable linear projection layers. These projected features then pass through specialized adapter modules that modify them for specific tasks while maintaining a connection to the original features through residual integration. The adapter modules implement a bottleneck architecture, reducing the feature dimension by a factor of 4 before restoration, allowing for efficient task-specific adaptations.</p> <h3 id="semantic-aware-classification">Semantic-Aware Classification</h3> <p>The classification mechanism employs a novel semantic-aware initialization strategy that leverages CLIP’s pre-trained understanding of concepts. This approach initializes classifier weights using CLIP’s semantic knowledge of the target classes, creating more meaningful decision boundaries from the start. The classification process uses cosine similarity with temperature scaling, allowing the model to make confident predictions while maintaining semantic relationships between features and class representations.</p> <h3 id="technical-implementation">Technical Implementation</h3> <p>The complete model comprises 3,675,136 parameters and implements several key technical components:</p> <ul> <li> <strong>Feature Projection</strong>: Configurable depth projection layers that map CLIP features to higher dimensions</li> <li> <strong>Adapter Modules</strong>: Bottleneck architecture for task-specific feature adaptation</li> <li> <strong>Residual Integration</strong>: Weighted combination of adapted and projected features (0.2:0.8 ratio)</li> <li> <strong>Cosine Classification</strong>: Temperature-scaled (30) cosine similarity for final predictions</li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/projects/meme_training.png" alt="MemeSense Training Process" title="MemeSense Training Process"> </div> </div> <div class="caption"> Training pipeline showing data processing, feature extraction, and classification components </div> <h3 id="performance-evaluation">Performance Evaluation</h3> <p>The system demonstrates strong performance across multiple classification tasks:</p> <ul> <li> <strong>Humor Recognition</strong>: 80.27% accuracy with 85.59% AUC</li> <li> <strong>Hate Speech Detection</strong>: 76.06% accuracy with 84.52% AUC</li> <li> <strong>Target Identification</strong>: 66.12% accuracy with 81.66% AUC</li> <li> <strong>Stance Classification</strong>: 62.00% accuracy with 80.11% AUC</li> </ul> <p>The model was trained on the PrideMM dataset comprising 5,063 annotated memes, with 4,666 samples for training and 397 for validation. Training utilized a batch size of 16, learning rate of 1e-4, and weight decay of 1e-4 over 10 epochs, employing Cross Entropy Loss with mean reduction for optimization.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Kishore Sampath. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>